{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from adjustText import adjust_text\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cooc.json', 'r') as f:\n",
    "    obj = json.load(f)\n",
    "cooc = obj['matrix']\n",
    "names = obj['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram the log-cooccurrences to figure out a good\n",
    "# cutoff for the weighting function.\n",
    "coocs = np.array(cooc).flatten()\n",
    "coocs = coocs[np.nonzero(coocs)]\n",
    "plt.hist(np.log10(coocs))\n",
    "plt.xlabel('log_10 cooccurrence')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "# Select a weighting cutoff based on a percentile.\n",
    "x_max = sorted(coocs)[len(coocs) // 2]\n",
    "print('selected x_max as', x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GloVe-style embeddings.\n",
    "\n",
    "n_stores = len(names)\n",
    "n_feats = 2\n",
    "features = nn.Parameter(torch.zeros(n_stores, n_feats))\n",
    "features_bias = nn.Parameter(torch.zeros(n_stores))\n",
    "contexts = nn.Parameter(torch.zeros(n_stores, n_feats))\n",
    "contexts_bias = nn.Parameter(torch.zeros(n_stores))\n",
    "cooc_matrix = torch.tensor(cooc).to(features)\n",
    "\n",
    "def glove_loss(alpha=0.75):\n",
    "    pred = (features @ contexts.T) + features_bias[:, None] + contexts_bias\n",
    "    targ = torch.where(cooc_matrix == 0, 0.0, torch.log(cooc_matrix))\n",
    "    weights = cooc_matrix.clamp(max=x_max) ** alpha\n",
    "    return (weights * (pred - targ)**2).mean()\n",
    "\n",
    "opt = Adam([features, features_bias, contexts, contexts_bias], lr=1e-2)\n",
    "losses = []\n",
    "for _ in tqdm(range(3000)):\n",
    "    loss = glove_loss()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, sorted(losses)[(8*len(losses))//10])\n",
    "plt.show()\n",
    "\n",
    "features = features.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.scatter(embedding[:, 0], embedding[:, 1])\n",
    "texts = [plt.text(embedding[i, 0], embedding[i, 1], name, ha='center', va='center') for i, name in enumerate(names)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations = np.array(cooc)\n",
    "# counts = np.diag(correlations)\n",
    "# correlations /= np.sqrt(counts[None] @ counts[:, None])\n",
    "# correlations[names.index('Starbucks')]\n",
    "correlations = obj['correlation']\n",
    "for i, (name, row) in enumerate(zip(names, correlations)):\n",
    "    row_copy = row.copy()\n",
    "    row_copy[i] = 0\n",
    "    max_idx = np.argmax(row_copy)\n",
    "    print(name, '<->', names[max_idx], row_copy[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(store):\n",
    "    idx = names.index(store)\n",
    "    row = obj['correlation'][idx].copy()\n",
    "    row[idx] = 0\n",
    "    indices = np.argsort(row)[::-1][:5]\n",
    "    print('Results for:', store)\n",
    "    for i in indices:\n",
    "        print(f\"{names[i]}: {row[i]}\")\n",
    "    print('----------------')\n",
    "\n",
    "most_similar(\"Sephora\")\n",
    "most_similar(\"Ulta Beauty\")\n",
    "most_similar(\"Victoria's Secret\")\n",
    "most_similar(\"Five Below\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
